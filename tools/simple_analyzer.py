#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆçŸ¥è¯†åº“åˆ†æå·¥å…·
æ— éœ€é¢å¤–ä¾èµ–åŒ…ï¼Œå¯ç›´æ¥è¿è¡Œ
"""

import os
import json
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict

def analyze_knowledge_base(base_path="."):
    """åˆ†æçŸ¥è¯†åº“ç»“æ„å’Œå†…å®¹å®Œæ•´æ€§"""
    
    print("ğŸ” å¼€å§‹åˆ†æçŸ¥è¯†åº“...")
    base_path = Path(base_path)
    
    # ç»Ÿè®¡æ•°æ®
    stats = {
        'total_directories': 0,
        'total_files': 0,
        'markdown_files': 0,
        'directories_without_overview': [],
        'incomplete_documents': [],
        'category_distribution': defaultdict(int)
    }
    
    # éå†æ‰€æœ‰ç›®å½•
    for root, dirs, files in os.walk(base_path):
        # è·³è¿‡éšè—ç›®å½•å’Œå·¥å…·ç›®å½•
        dirs[:] = [d for d in dirs if not d.startswith('.') and d != 'tools' and d != '__pycache__']
        
        rel_path = Path(root).relative_to(base_path)
        if str(rel_path) == '.':
            continue
            
        stats['total_directories'] += 1
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰€éœ€çš„æ¦‚è§ˆæ–‡ä»¶
        md_files = [f for f in files if f.endswith('.md')]
        stats['total_files'] += len(files)
        stats['markdown_files'] += len(md_files)
        
        overview_files = ['Overview.md', 'æ€»è§ˆ.md', 'ç®€ä»‹.md', 'æ¦‚è¿°.md']
        has_overview = any(ov in md_files for ov in overview_files)
        
        if not has_overview and md_files:
            stats['directories_without_overview'].append(str(rel_path))
        
        # åˆ†ææ–‡æ¡£ç±»åˆ«
        dir_name = rel_path.name.lower()
        if 'therapy' in dir_name or 'æ²»ç–—' in dir_name:
            stats['category_distribution']['æ²»ç–—ç±»'] += 1
        elif 'assessment' in dir_name or 'è¯„ä¼°' in dir_name:
            stats['category_distribution']['è¯„ä¼°ç±»'] += 1
        elif 'research' in dir_name or 'ç ”ç©¶' in dir_name:
            stats['category_distribution']['ç ”ç©¶ç±»'] += 1
        else:
            stats['category_distribution']['å…¶ä»–ç±»'] += 1
        
        # æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
        for md_file in md_files:
            file_path = Path(root) / md_file
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
                if len(content.strip()) < 300:
                    stats['incomplete_documents'].append(str(file_path.relative_to(base_path)))
                elif not content.strip().startswith('#'):
                    stats['incomplete_documents'].append(str(file_path.relative_to(base_path)))
                    
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'analysis_timestamp': datetime.now().isoformat(),
        'summary': {
            'æ€»ç›®å½•æ•°': stats['total_directories'],
            'æ€»æ–‡ä»¶æ•°': stats['total_files'],
            'Markdownæ–‡æ¡£æ•°': stats['markdown_files'],
            'ç¼ºå°‘æ¦‚è§ˆæ–‡æ¡£çš„ç›®å½•æ•°': len(stats['directories_without_overview']),
            'ä¸å®Œæ•´æ–‡æ¡£æ•°': len(stats['incomplete_documents'])
        },
        'missing_overviews': sorted(stats['directories_without_overview']),
        'incomplete_docs': sorted(stats['incomplete_documents']),
        'category_distribution': dict(stats['category_distribution']),
        'completion_rate': round(
            (stats['total_directories'] - len(stats['directories_without_overview'])) / 
            max(1, stats['total_directories']) * 100, 1
        ) if stats['total_directories'] > 0 else 0
    }
    
    return report

def check_document_quality(file_path):
    """æ£€æŸ¥å•ä¸ªæ–‡æ¡£çš„è´¨é‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        quality_score = 100
        issues = []
        
        # æ ‡é¢˜æ£€æŸ¥
        if not content.strip().startswith('#'):
            quality_score -= 20
            issues.append("ç¼ºå°‘æ ‡é¢˜")
        
        # é•¿åº¦æ£€æŸ¥
        if len(content.strip()) < 500:
            quality_score -= 15
            issues.append("å†…å®¹è¿‡çŸ­")
        
        # ç« èŠ‚ç»“æ„æ£€æŸ¥
        section_headers = len(re.findall(r'^#+\s', content, re.MULTILINE))
        if section_headers < 2:
            quality_score -= 10
            issues.append("ç« èŠ‚ç»“æ„ä¸å®Œæ•´")
        
        # ä¸­è‹±æ–‡æ··åˆæ£€æŸ¥
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
        english_chars = len(re.findall(r'[a-zA-Z]', content))
        if chinese_chars > 0 and english_chars > 0:
            ratio = english_chars / (chinese_chars + english_chars)
            if ratio > 0.4:
                quality_score -= 5
                issues.append(f"è‹±æ–‡æ¯”ä¾‹è¿‡é«˜ ({ratio:.1%})")
        
        return {
            'file': str(file_path),
            'score': max(0, quality_score),
            'issues': issues,
            'status': 'åˆæ ¼' if quality_score >= 80 else 'éœ€æ”¹è¿›' if quality_score >= 60 else 'ä¸åˆæ ¼'
        }
        
    except Exception as e:
        return {
            'file': str(file_path),
            'score': 0,
            'issues': [f'è¯»å–é”™è¯¯: {str(e)}'],
            'status': 'é”™è¯¯'
        }

def generate_quality_report(base_path="."):
    """ç”Ÿæˆæ–‡æ¡£è´¨é‡æŠ¥å‘Š"""
    print("ğŸ“‹ å¼€å§‹ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
    
    base_path = Path(base_path)
    md_files = list(base_path.rglob("*.md"))
    
    quality_results = []
    scores = []
    
    for md_file in md_files:
        # è·³è¿‡å·¥å…·ç›®å½•ä¸­çš„æ–‡ä»¶
        if 'tools' in str(md_file):
            continue
            
        result = check_document_quality(md_file)
        quality_results.append(result)
        scores.append(result['score'])
    
    # ç»Ÿè®¡ç»“æœ
    passed = len([r for r in quality_results if r['status'] == 'åˆæ ¼'])
    needs_improvement = len([r for r in quality_results if r['status'] == 'éœ€æ”¹è¿›'])
    failed = len([r for r in quality_results if r['status'] == 'ä¸åˆæ ¼'])
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'æ€»æ–‡æ¡£æ•°': len(quality_results),
            'åˆæ ¼æ–‡æ¡£': passed,
            'éœ€æ”¹è¿›æ–‡æ¡£': needs_improvement,
            'ä¸åˆæ ¼æ–‡æ¡£': failed,
            'å¹³å‡åˆ†æ•°': round(sum(scores) / len(scores), 1) if scores else 0,
            'åˆæ ¼ç‡': round(passed / len(quality_results) * 100, 1) if quality_results else 0
        },
        'detailed_results': sorted(quality_results, key=lambda x: x['score'], reverse=True),
        'top_issues': {}  # å¯ä»¥æ‰©å±•ç»Ÿè®¡æœ€å¸¸è§çš„é—®é¢˜
    }
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  å¹³é™å®éªŒå®¤çŸ¥è¯†åº“åˆ†æå·¥å…·")
    print("=" * 50)
    
    # åˆ†æçŸ¥è¯†åº“ç»“æ„
    structure_report = analyze_knowledge_base("..")
    
    print(f"\nğŸ“Š çŸ¥è¯†åº“ç»“æ„åˆ†æç»“æœ:")
    print(f"ğŸ“ æ€»ç›®å½•æ•°: {structure_report['summary']['æ€»ç›®å½•æ•°']}")
    print(f"ğŸ“„ Markdownæ–‡æ¡£æ•°: {structure_report['summary']['Markdownæ–‡æ¡£æ•°']}")
    print(f"âŒ ç¼ºå°‘æ¦‚è§ˆæ–‡æ¡£çš„ç›®å½•: {structure_report['summary']['ç¼ºå°‘æ¦‚è§ˆæ–‡æ¡£çš„ç›®å½•æ•°']} ä¸ª")
    print(f"âš ï¸  ä¸å®Œæ•´æ–‡æ¡£: {structure_report['summary']['ä¸å®Œæ•´æ–‡æ¡£æ•°']} ä¸ª")
    print(f"âœ… å®Œæ•´åº¦: {structure_report['completion_rate']}%")
    
    # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    quality_report = generate_quality_report("..")
    
    print(f"\nğŸ“ˆ æ–‡æ¡£è´¨é‡åˆ†æç»“æœ:")
    print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {quality_report['summary']['æ€»æ–‡æ¡£æ•°']}")
    print(f"âœ… åˆæ ¼æ–‡æ¡£: {quality_report['summary']['åˆæ ¼æ–‡æ¡£']} ({quality_report['summary']['åˆæ ¼ç‡']}%)")
    print(f"âš ï¸  éœ€æ”¹è¿›æ–‡æ¡£: {quality_report['summary']['éœ€æ”¹è¿›æ–‡æ¡£']}")
    print(f"âŒ ä¸åˆæ ¼æ–‡æ¡£: {quality_report['summary']['ä¸åˆæ ¼æ–‡æ¡£']}")
    print(f"ğŸ’¯ å¹³å‡åˆ†æ•°: {quality_report['summary']['å¹³å‡åˆ†æ•°']}")
    
    # ä¿å­˜æŠ¥å‘Š
    with open('knowledge_base_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(structure_report, f, ensure_ascii=False, indent=2)
    
    with open('quality_report.json', 'w', encoding='utf-8') as f:
        json.dump(quality_report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜:")
    print(f"   - çŸ¥è¯†åº“ç»“æ„åˆ†æ: knowledge_base_analysis.json")
    print(f"   - æ–‡æ¡£è´¨é‡æŠ¥å‘Š: quality_report.json")
    
    # æ˜¾ç¤ºéœ€è¦å…³æ³¨çš„é—®é¢˜
    if structure_report['missing_overviews']:
        print(f"\nğŸ”” éœ€è¦è¡¥å……æ¦‚è§ˆæ–‡æ¡£çš„ç›®å½•:")
        for dir_path in structure_report['missing_overviews'][:10]:
            print(f"   - {dir_path}")
        if len(structure_report['missing_overviews']) > 10:
            print(f"   ... è¿˜æœ‰ {len(structure_report['missing_overviews']) - 10} ä¸ªç›®å½•")
    
    low_quality_docs = [r for r in quality_report['detailed_results'] if r['score'] < 70]
    if low_quality_docs:
        print(f"\nâš ï¸  è´¨é‡è¾ƒä½çš„æ–‡æ¡£ (åˆ†æ•° < 70):")
        for doc in low_quality_docs[:5]:
            print(f"   - {doc['file']}: {doc['score']}åˆ† ({', '.join(doc['issues'])})")
        if len(low_quality_docs) > 5:
            print(f"   ... è¿˜æœ‰ {len(low_quality_docs) - 5} ä¸ªæ–‡æ¡£éœ€è¦æ”¹è¿›")

if __name__ == "__main__":
    main()