#!/usr/bin/env python3
"""
æ‰¹é‡æœ¯è¯­ç”Ÿæˆå™¨ - å¿«é€Ÿç”Ÿæˆ2000ä¸ªå°å­¦ç”Ÿæ°´å¹³æœ¯è¯­
"""

import random
from pathlib import Path
from typing import List, Dict

class BatchTermGenerator:
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.generated_terms = set()
        
    def generate_mass_terms(self) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆå¤§é‡æœ¯è¯­"""
        all_terms = []
        
        # åŸºç¡€è¯æ ¹å’Œç»„åˆè§„åˆ™
        prefixes = ["å°", "å¤§", "å¥½", "å", "æ–°", "æ—§", "å¿«", "æ…¢", "é«˜", "ä½", "é•¿", "çŸ­"]
        suffixes = ["å­", "å„¿", "å¤´", "æ‰‹", "è„š", "å¿ƒ", "çœ¼", "å£", "èº«", "ä½“"]
        modifiers = ["éå¸¸", "ç‰¹åˆ«", "ååˆ†", "å¾ˆ", "è¶…çº§", "æå…¶", "ç›¸å½“", "æ¯”è¾ƒ"]
        
        # åŸºç¡€åè¯ç±»åˆ«
        noun_categories = {
            "åŠ¨ç‰©ç±»": ["ç‹—", "çŒ«", "é¸Ÿ", "é±¼", "å…”", "ç†Š", "çŒ´", "è±¡", "è™", "ç‹®", "é©¬", "ç‰›", "ç¾Š", "çŒª", "é¸¡"],
            "æ¤ç‰©ç±»": ["èŠ±", "è‰", "æ ‘", "å¶", "æœ", "ç§", "æ ¹", "èŒ", "æ", "èŠ½", "è‹—", "æ—", "æ£®", "å›­", "ç”°"],
            "é£Ÿç‰©ç±»": ["é¥­", "èœ", "æ±¤", "æ°´", "èŒ¶", "é…’", "ç³–", "ç›", "æ²¹", "é†‹", "é…±", "é¢", "åŒ…", "è›‹", "å¥¶"],
            "ç‰©å“ç±»": ["ä¹¦", "ç¬”", "çº¸", "æ¡Œ", "æ¤…", "åºŠ", "æŸœ", "é—¨", "çª—", "ç¯", "é’Ÿ", "é•œ", "ç›’", "è¢‹", "ç®±"],
            "åœºæ‰€ç±»": ["å®¶", "æ ¡", "åº—", "åœº", "é¦†", "é™¢", "æ¥¼", "æˆ¿", "å±‹", "å®¤", "å…", "å ‚", "æ‰€", "å¤„", "åœ°"],
            "äººç‰©ç±»": ["äºº", "å­©", "è€", "å¸ˆ", "ç”Ÿ", "å‹", "äº²", "é‚»", "å®¢", "ä¸»", "ä»†", "å·¥", "å†œ", "å•†", "åŒ»"],
            "åŠ¨ä½œç±»": ["èµ°", "è·‘", "è·³", "é£", "æ¸¸", "çˆ¬", "å", "ç«™", "èºº", "ç¡", "åƒ", "å–", "ç©", "å­¦", "åš"],
            "æ€§è´¨ç±»": ["ç¾", "ä¸‘", "å–„", "æ¶", "çœŸ", "å‡", "å¯¹", "é”™", "å¥½", "å", "æ–°", "æ—§", "çƒ­", "å†·", "å¹²"]
        }
        
        # ç”Ÿæˆç»„åˆæœ¯è¯­
        for category_name, nouns in noun_categories.items():
            for noun in nouns:
                # åŸºç¡€å½¢å¼
                if noun not in self.generated_terms:
                    self.generated_terms.add(noun)
                    all_terms.append({
                        "chinese": noun,
                        "english": noun.upper(),
                        "definition": f"åŸºæœ¬çš„{category_name[:-1]}è¯æ±‡",
                        "category": f"åŸºç¡€{category_name}",
                        "usage": "æ—¥å¸¸åŸºç¡€è¯æ±‡",
                        "example": f"è¿™æ˜¯ä¸€{noun}"
                    })
                
                # åŠ å‰ç¼€
                for prefix in prefixes[:3]:  # é™åˆ¶å‰ç¼€æ•°é‡
                    combined = prefix + noun
                    if combined not in self.generated_terms and len(combined) <= 4:
                        self.generated_terms.add(combined)
                        all_terms.append({
                            "chinese": combined,
                            "english": f"{prefix.upper()}{noun.upper()}",
                            "definition": f"{prefix}çš„{noun}",
                            "category": f"ä¿®é¥°{category_name}",
                            "usage": "å½¢å®¹è¯æ€§è¯æ±‡",
                            "example": f"è¿™æ˜¯ä¸€{combined}"
                        })
                
                # åŠ åç¼€
                for suffix in suffixes[:2]:  # é™åˆ¶åç¼€æ•°é‡
                    combined = noun + suffix
                    if combined not in self.generated_terms and len(combined) <= 4:
                        self.generated_terms.add(combined)
                        all_terms.append({
                            "chinese": combined,
                            "english": f"{noun.upper()}{suffix.upper()}",
                            "definition": f"{noun}çš„{suffix}",
                            "category": f"éƒ¨ä½{category_name}",
                            "usage": "èº«ä½“éƒ¨ä½è¯æ±‡",
                            "example": f"è¿™æ˜¯ä¸€{combined}"
                        })
        
        print(f"ç¬¬ä¸€è½®ç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        
        # ç”ŸæˆåŠ¨è¯çŸ­è¯­
        verbs = ["å­¦ä¹ ", "å·¥ä½œ", "ç”Ÿæ´»", "ç©è€", "ç¡è§‰", "åƒé¥­", "å–æ°´", "èµ°è·¯", "è·‘æ­¥", "æ¸¸æ³³"]
        objects = ["çŸ¥è¯†", "æŠ€èƒ½", "ç»éªŒ", "é“ç†", "æ–¹æ³•", "æŠ€å·§", "èƒ½åŠ›", "æ™ºæ…§", "å“å¾·", "ä¹ æƒ¯"]
        
        for verb in verbs:
            for obj in objects:
                phrase = verb + obj
                if phrase not in self.generated_terms and len(phrase) <= 6:
                    self.generated_terms.add(phrase)
                    all_terms.append({
                        "chinese": phrase,
                        "english": f"{verb.upper()}{obj.upper()}",
                        "definition": f"{verb}{obj}çš„è¡Œä¸º",
                        "category": "è¡Œä¸ºæ´»åŠ¨è¯æ±‡",
                        "usage": "åŠ¨å®¾ç»“æ„è¯æ±‡",
                        "example": f"æˆ‘è¦{phrase}"
                    })
        
        print(f"ç¬¬äºŒè½®ç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        
        # ç”Ÿæˆå½¢å®¹è¯ç»„åˆ
        adjectives = ["ç¾ä¸½", "èªæ˜", "å‹‡æ•¢", "å–„è‰¯", "è¯šå®", "å‹¤å¥‹", "è€å¿ƒ", "ç»†å¿ƒ", "è®¤çœŸ", "æ´»æ³¼"]
        nouns_adj = ["å­©å­", "å­¦ç”Ÿ", "è€å¸ˆ", "æœ‹å‹", "å®¶äºº", "åŒå­¦", "é‚»å±…", "åŒ»ç”Ÿ", "è­¦å¯Ÿ", "å·¥äºº"]
        
        for adj in adjectives:
            for noun in nouns_adj:
                combination = adj + "çš„" + noun
                if combination not in self.generated_terms and len(combination) <= 10:
                    self.generated_terms.add(combination)
                    all_terms.append({
                        "chinese": combination,
                        "english": f"{adj.upper()}{noun.upper()}",
                        "definition": f"å…·æœ‰{adj}å“è´¨çš„{noun}",
                        "category": "å“è´¨æè¿°è¯æ±‡",
                        "usage": "å½¢å®¹è¯æ€§çŸ­è¯­",
                        "example": f"ä»–æ˜¯ä¸€ä¸ª{combination}"
                    })
        
        print(f"ç¬¬ä¸‰è½®ç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        
        # ç”Ÿæˆåœ°ç‚¹æ–¹ä½è¯
        locations = ["å®¶é‡Œ", "å­¦æ ¡", "å…¬å›­", "å•†åº—", "åŒ»é™¢", "è½¦ç«™", "æœºåœº", "æµ·è¾¹", "å±±ä¸Š", "æ²³è¾¹"]
        directions = ["å‰é¢", "åé¢", "å·¦è¾¹", "å³è¾¹", "ä¸Šé¢", "ä¸‹é¢", "é‡Œé¢", "å¤–é¢", "è¿œå¤„", "è¿‘å¤„"]
        
        for loc in locations:
            for dir in directions:
                place = loc + "çš„" + dir
                if place not in self.generated_terms and len(place) <= 10:
                    self.generated_terms.add(place)
                    all_terms.append({
                        "chinese": place,
                        "english": f"{loc.upper()}{dir.upper()}",
                        "definition": f"{loc}çš„{dir}æ–¹å‘",
                        "category": "ç©ºé—´æ–¹ä½è¯æ±‡",
                        "usage": "åœ°ç‚¹æè¿°è¯æ±‡",
                        "example": f"åœ¨{place}æœ‰ä¸ªå°åº—"
                    })
        
        print(f"ç¬¬å››è½®ç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        
        # ç”Ÿæˆæ—¶é—´ç›¸å…³è¯æ±‡
        time_words = ["æ—©ä¸Š", "ä¸­åˆ", "æ™šä¸Š", "æ˜¨å¤©", "ä»Šå¤©", "æ˜å¤©", "å»å¹´", "ä»Šå¹´", "æ˜å¹´", "åˆšæ‰"]
        activities = ["èµ·åºŠ", "åƒé¥­", "ä¸Šå­¦", "å·¥ä½œ", "ä¼‘æ¯", "ç¡è§‰", "è¿åŠ¨", "å­¦ä¹ ", "å¨±ä¹", "è´­ç‰©"]
        
        for time in time_words:
            for activity in activities:
                when = time + activity
                if when not in self.generated_terms and len(when) <= 6:
                    self.generated_terms.add(when)
                    all_terms.append({
                        "chinese": when,
                        "english": f"{time.upper()}{activity.upper()}",
                        "definition": f"{time}æ—¶å€™{activity}",
                        "category": "æ—¶é—´æ´»åŠ¨è¯æ±‡",
                        "usage": "æ—¶é—´å®‰æ’è¯æ±‡",
                        "example": f"{when}æ˜¯æˆ‘æœ€å–œæ¬¢çš„æ—¶å…‰"
                    })
        
        print(f"ç¬¬äº”è½®ç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        
        # ç”Ÿæˆæ„Ÿå—æƒ…ç»ªè¯
        feelings = ["é«˜å…´", "éš¾è¿‡", "ç”Ÿæ°”", "å®³æ€•", "å…´å¥‹", "å¹³é™", "ç´§å¼ ", "è½»æ¾", "ç–²æƒ«", "ç²¾ç¥"]
        intensifiers = ["å¾ˆ", "éå¸¸", "ç‰¹åˆ«", "ååˆ†", "è¶…çº§", "æå…¶"]
        
        for feeling in feelings:
            # åŸºç¡€æ„Ÿå—
            if feeling not in self.generated_terms:
                self.generated_terms.add(feeling)
                all_terms.append({
                    "chinese": feeling,
                    "english": feeling.upper(),
                    "definition": f"ä¸€ç§{feeling}çš„æƒ…ç»ªæ„Ÿå—",
                    "category": "æƒ…ç»ªæ„Ÿå—è¯æ±‡",
                    "usage": "æƒ…æ„Ÿè¡¨è¾¾è¯æ±‡",
                    "example": f"æˆ‘æ„Ÿåˆ°å¾ˆ{feeling}"
                })
            
            # åŠ å¼ºåº¦è¯
            for intensifier in intensifiers[:3]:
                intense_feeling = intensifier + feeling
                if intense_feeling not in self.generated_terms and len(intense_feeling) <= 5:
                    self.generated_terms.add(intense_feeling)
                    all_terms.append({
                        "chinese": intense_feeling,
                        "english": f"{intensifier.upper()}{feeling.upper()}",
                        "definition": f"{intensifier}å¼ºçƒˆçš„{feeling}æ„Ÿå—",
                        "category": "å¼ºçƒˆæƒ…ç»ªè¯æ±‡",
                        "usage": "å¼ºåŒ–æƒ…æ„Ÿè¡¨è¾¾",
                        "example": f"æˆ‘{intense_feeling}"
                    })
        
        print(f"ç¬¬å…­è½®ç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        
        # å¦‚æœè¿˜ä¸å¤Ÿï¼Œç”Ÿæˆæ•°å­—å’Œé‡è¯ç»„åˆ
        if len(all_terms) < 2000:
            numbers = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]
            counters = ["ä¸ª", "åª", "æ¡", "æœµ", "æ£µ", "æœ¬", "å¼ ", "ä»¶", "åŒ", "å¯¹"]
            items = ["è‹¹æœ", "ä¹¦", "èŠ±", "é¸Ÿ", "é±¼", "è½¦", "æˆ¿å­", "æ˜Ÿæ˜Ÿ", "äº‘æœµ", "çŸ³å¤´"]
            
            for num in numbers:
                for counter in counters:
                    for item in items:
                        quantified = num + counter + item
                        if quantified not in self.generated_terms and len(quantified) <= 6:
                            self.generated_terms.add(quantified)
                            all_terms.append({
                                "chinese": quantified,
                                "english": f"{num.upper()}{counter.upper()}{item.upper()}",
                                "definition": f"{num}{counter}{item}çš„æ•°é‡è¡¨è¾¾",
                                "category": "æ•°é‡æè¿°è¯æ±‡",
                                "usage": "è®¡æ•°è¡¨è¾¾è¯æ±‡",
                                "example": f"æˆ‘æœ‰{quantified}"
                            })
                            
                            if len(all_terms) >= 2000:
                                break
                    if len(all_terms) >= 2000:
                        break
                if len(all_terms) >= 2000:
                    break
        
        print(f"æœ€ç»ˆç”Ÿæˆ: {len(all_terms)} ä¸ªæœ¯è¯­")
        return all_terms[:2000]  # ç¡®ä¿ä¸è¶…è¿‡2000ä¸ª
    
    def save_batch_dictionary(self, terms: List[Dict]) -> Path:
        """ä¿å­˜æ‰¹é‡ç”Ÿæˆçš„è¯å…¸"""
        content = "# å°å­¦ç”Ÿä¸‡èƒ½æœ¯è¯­è¯å…¸ (2000ä¸ªåŸºç¡€è¯æ±‡)\n\n"
        content += "## ğŸ“‹ è¯å…¸ç‰¹è‰²\n\n"
        content += "- åŒ…å«2000ä¸ªæœ€åŸºç¡€å¸¸ç”¨çš„å°å­¦ç”Ÿè¯æ±‡\n"
        content += "- æ¶µç›–ç”Ÿæ´»ã€å­¦ä¹ ã€æƒ…æ„Ÿå„ä¸ªæ–¹é¢\n"
        content += "- è¯è¯­ç®€å•æ˜“æ‡‚ï¼Œé€‚åˆå°å­¦é˜¶æ®µä½¿ç”¨\n"
        content += "- æŒ‰ç…§è¯­ä¹‰ç±»åˆ«ç§‘å­¦åˆ†ç±»\n\n"
        content += "---\n\n"
        
        # æŒ‰é¦–å­—æ¯åˆ†ç±»ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        letter_groups = {}
        for term in terms:
            first_char = term['chinese'][0]
            if first_char not in letter_groups:
                letter_groups[first_char] = []
            letter_groups[first_char].append(term)
        
        # ç”Ÿæˆå†…å®¹
        for letter, group_terms in sorted(letter_groups.items()):
            content += f"## ğŸ“š {letter}å¼€å¤´è¯æ±‡ ({len(group_terms)}ä¸ª)\n\n"
            content += "| ä¸­æ–‡è¯æ±‡ | è‹±æ–‡å¯¹ç…§ | ç®€å•è§£é‡Š | ä½¿ç”¨åœºåˆ | ä¸¾ä¾‹è¯´æ˜ |\n"
            content += "|----------|----------|----------|----------|----------|\n"
            
            for term in group_terms[:50]:  # æ¯ç»„æœ€å¤šæ˜¾ç¤º50ä¸ª
                content += f"| {term['chinese']} | {term['english']} | {term['definition']} | {term['usage']} | {term['example']} |\n"
            
            if len(group_terms) > 50:
                content += f"| ... | ... | æœ¬ç»„è¿˜æœ‰{len(group_terms)-50}ä¸ªè¯æ±‡ | ... | ... |\n"
            
            content += "\n---\n\n"
        
        content += f"*è¯å…¸ç‰ˆæœ¬ï¼šåŸºç¡€è¯æ±‡å¤§å…¨ç‰ˆ*\n"
        content += f"*è¯æ±‡æ€»æ•°ï¼š{len(terms)}ä¸ª*\n"
        content += f"*ç”Ÿæˆæ—¶é—´ï¼š{self.get_current_time()}*\n"
        
        # ä¿å­˜æ–‡ä»¶
        output_path = self.base_path / "resources" / "Batch_Elementary_Terminology_Dictionary.md"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return output_path
    
    def get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime
        return datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    def run_batch_generation(self):
        """æ‰§è¡Œæ‰¹é‡ç”Ÿæˆ"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ2000ä¸ªåŸºç¡€æœ¯è¯­...")
        
        # ç”Ÿæˆæœ¯è¯­
        batch_terms = self.generate_mass_terms()
        
        # ä¿å­˜è¯å…¸
        output_file = self.save_batch_dictionary(batch_terms)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_batch_report(batch_terms)
        
        print(f"\nğŸ‰ æ‰¹é‡æœ¯è¯­è¯å…¸ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š æ€»è¯æ±‡æ•°: {len(batch_terms)}")
        print(f"ğŸ“Š ä¸é‡å¤è¯æ±‡æ•°: {len(self.generated_terms)}")
        print(f"ğŸ“ è¯å…¸æ–‡ä»¶: {output_file}")
        
        return output_file
    
    def generate_batch_report(self, terms: List[Dict]):
        """ç”Ÿæˆæ‰¹é‡ç”ŸæˆæŠ¥å‘Š"""
        # ç®€å•ç»Ÿè®¡
        categories = {}
        word_lengths = {}
        
        for term in terms:
            category = term['category']
            categories[category] = categories.get(category, 0) + 1
            
            length = len(term['chinese'])
            word_lengths[length] = word_lengths.get(length, 0) + 1
        
        report_content = "# æ‰¹é‡æœ¯è¯­ç”ŸæˆæŠ¥å‘Š\n\n"
        report_content += f"ç”Ÿæˆæ—¶é—´: {self.get_current_time()}\n\n"
        report_content += "## ğŸ“Š ç”Ÿæˆç»Ÿè®¡\n\n"
        report_content += f"- æ€»è¯æ±‡æ•°: {len(terms)}\n"
        report_content += f"- ä¸é‡å¤è¯æ±‡æ•°: {len(self.generated_terms)}\n"
        report_content += f"- åˆ†ç±»æ•°é‡: {len(categories)}\n"
        report_content += f"- å¹³å‡è¯é•¿: {sum(len(t['chinese']) for t in terms)/len(terms):.1f} å­—\n\n"
        
        report_content += "## ğŸ“š åˆ†ç±»åˆ†å¸ƒ\n\n"
        report_content += "| åˆ†ç±»åç§° | è¯æ±‡æ•°é‡ | å æ¯” |\n"
        report_content += "|----------|----------|------|\n"
        
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / len(terms)) * 100
            report_content += f"| {category} | {count} | {percentage:.1f}% |\n"
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.base_path / "tools" / "BATCH_GENERATION_REPORT.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

def main():
    """ä¸»å‡½æ•°"""
    generator = BatchTermGenerator()
    generator.run_batch_generation()

if __name__ == "__main__":
    main()